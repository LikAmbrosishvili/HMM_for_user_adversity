{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.          0.45964749]\n",
      " [16.          0.82164065]\n",
      " [19.          0.22814685]\n",
      " [ 0.          0.        ]\n",
      " [ 4.          0.10875466]\n",
      " [16.          0.40066903]\n",
      " [19.          0.5806915 ]\n",
      " [ 3.          0.20518074]\n",
      " [18.          0.        ]\n",
      " [17.          0.63280949]]\n",
      "\n",
      "Predicted Hidden State Transitions:\n",
      "[1 0 0 2 0 1 1 1 1 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "from hmmlearn import hmm\n",
    "import numpy as np \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "np.random.seed(42)\n",
    "\n",
    "model  = hmm.GaussianHMM( n_components = 3, init_params = '', covariance_type=\"full\",  random_state= 4)\n",
    "\n",
    "model.startprob_= np.array([0.3, 0.3, 0.4])\n",
    "\n",
    "#  Transition Probs: 0 - Engaged; 1 - Confused; 2 - Frustrated.\n",
    "model.transmat_= np.array([\n",
    "    [0.5, 0.2, 0.3], \n",
    "    [0.2, 0.6, 0.2],\n",
    "    [0.2, 0.3, 0.5] ]) \n",
    "\n",
    "#first column is mouse clicks let's say and second one (0.1, 0.3, 0.5) are error rates \n",
    "model.means_  = np.array([[3.0,  0.1], \n",
    "                         [10.0, 0.3], \n",
    "                         [20.0, 0.5] ])\n",
    "model.covars_ = np.array([ [[1.0, 0.05], [0.05, 0.02]],\n",
    "                           [[2.0, 0.10], [0.10, 0.05]], \n",
    "                           [[3.0, 0.20], [0.20, 0.10]]])\n",
    "\n",
    "n_samples = 100\n",
    "\n",
    "trials, simulated_states = model.sample(n_samples)\n",
    "trials[:, 0] = np.random.poisson(lam=trials[:, 0]).astype(int)\n",
    "trials[:, 1] = np.clip(trials[:, 1], 0, 1)\n",
    "\n",
    "predicted_states = model.predict(trials)\n",
    "\n",
    "print(trials[:10])\n",
    "\n",
    "X_train = trials[:trials.shape[0] //2]\n",
    "X_test = trials[trials.shape[0] // 2:]\n",
    "\n",
    "\n",
    "#model.fit(X_train)\n",
    "\n",
    "experiment_observations = np.array([[13.0, 0.4], [0.0, 0.1], [1.0, 0.2],\n",
    "                                    [15.0, 0.5], [1.0, 0.1], [10.0, 0.3],\n",
    "                                    [10.0, 0.4], [12.0, 0.5],[9.0, 0.3], \n",
    "                                    [0.0, 0.05], [20.0, 0.6],[23.0, 0.7]])\n",
    "\n",
    "predicted_states_obs = model.predict(experiment_observations)\n",
    "\n",
    "print(\"\\nPredicted Hidden State Transitions:\")\n",
    "print(predicted_states_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn.hmm import MultinomialHMM\n",
    "from hmmlearn import hmm\n",
    "import numpy as np \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/likaambrosishvili/ISIR/HMM/Multi_Ghmm.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/likaambrosishvili/ISIR/HMM/Multi_Ghmm.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39msklearn\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m cluster\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/likaambrosishvili/ISIR/HMM/Multi_Ghmm.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m multivariate_normal\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/likaambrosishvili/ISIR/HMM/Multi_Ghmm.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m BaseHMM\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/likaambrosishvili/ISIR/HMM/Multi_Ghmm.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/likaambrosishvili/ISIR/HMM/Multi_Ghmm.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     init_covars, fill_covars, validate_covars, normalise,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/likaambrosishvili/ISIR/HMM/Multi_Ghmm.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     concatenate_observation_sequences, check_if_attributes_set\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/likaambrosishvili/ISIR/HMM/Multi_Ghmm.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/likaambrosishvili/ISIR/HMM/Multi_Ghmm.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m COVARIANCE_TYPES \u001b[39m=\u001b[39m \u001b[39mfrozenset\u001b[39m((\u001b[39m'\u001b[39m\u001b[39mdiagonal\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtied\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mspherical\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Jan 15, 2020\n",
    "@authors: semese, fmorenopino\n",
    "This code is based on:\n",
    "  - HMM implementation by guyz- https://github.com/guyz/HMM\n",
    "  - hmmlearn by anntzer - https://github.com/hmmlearn/\n",
    "  - HMM with labels implementation by fmorenopino: https://github.com/fmorenopino/HMM_eb2\n",
    "For theoretical bases see:\n",
    " - L. R. Rabiner, 'A tutorial on hidden Markov models and selected applications\n",
    "   in speech recognition,' in Proceedings of the IEEE, vol. 77, no. 2,\n",
    "   pp. 257-286, Feb. 1989.\n",
    " - K.P. Murphy, 'Machine Learning: A Probabilistic Perspective', The MIT Press\n",
    "   Â©2012, ISBN:0262018020 9780262018029\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import cluster\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from .base import BaseHMM\n",
    "from .utils import (\n",
    "    init_covars, fill_covars, validate_covars, normalise,\n",
    "    concatenate_observation_sequences, check_if_attributes_set\n",
    ")\n",
    "\n",
    "COVARIANCE_TYPES = frozenset(('diagonal', 'full', 'tied', 'spherical'))\n",
    "\n",
    "\n",
    "class HeterogeneousHMM(BaseHMM):\n",
    "    \"\"\"Implementation of HMM with labels. It can manage Gaussian and categorical features.  \n",
    "\n",
    "    :param n_states: number of hidden states in the model\n",
    "    :type n_states: int\n",
    "    :param n_g_emissions: number of Gaussian features\n",
    "    :type n_g_emissions: int\n",
    "    :param n_d_emissions: number of categorical features\n",
    "    :type n_d_emissions: int\n",
    "    :param n_d_features: number of distinct observation symbols per state\n",
    "    :type n_d_features: list\n",
    "    :param tr_params: controls which parameters are updated in thetraining process; can contain any combination of 's' for startingprobabilities (pi), 't' for transition matrix, and other charactersfor subclass-specific emission parameters, defaults to 'stmce'\n",
    "    :type tr_params: str, optional\n",
    "    :param init_params: controls which parameters are initialised prior to training.  Can contain any combination of 's' for starting probabilities (pi), 't' for transition matrix, and other characters for subclass-specific emission parameters, defaults to 'stmce'\n",
    "    :type init_params: str, optional\n",
    "    :param nr_no_train_de: this number indicates the number of discrete emissions whose Matrix Emission Probabilities are fixed and are not trained; it is important to to order the observed variables such that the ones whose emissions aren't trained are the last ones, defaults to 0\n",
    "    :type nr_no_train_de: int, optional\n",
    "    :param state_no_train_de: a state index for nr_no_train_de which shouldn't be updated; defaults to None, which means that the entire emission probability matrix for that discrete emission will be kept unchanged during training, otherwise the last state_no_train_de states won't be updated, defaults to None\n",
    "    :type state_no_train_de: int, optional\n",
    "    :param covariance_type: string describing the type of covariance parameters to use. Defaults to 'full'.\n",
    "    :type covariance_type: str, optional\n",
    "    :param pi_prior: array of shape (n_states, ) setting the parameters of the Dirichlet prior distribution for the starting probabilities. Defaults to 1.\n",
    "    :type pi_prior: array_like, optional \n",
    "    :param pi: array of shape (n_states, ) giving the initial state occupation distribution 'pi'\n",
    "    :type pi: array_like\n",
    "    :param A_prior: array of shape (n_states, ), giving the parameters of the Dirichlet prior distribution for each row of the transition probabilities 'A'. Defaults to 1.\n",
    "    :type A_prior: array_like, optional \n",
    "    :param A: array of shape (n_states, n_states) giving the matrix of transition probabilities between states\n",
    "    :type A: array_like\n",
    "    :param B: the probabilities of emitting a given discrete symbol when in each state\n",
    "    :type B: list\n",
    "    :param means_prior: array of shape (n_states, 1), the mean of the Normal prior distribution for the means. Defaults to 0.\n",
    "    :type means_prior: array_like, optional \n",
    "    :param means_weight: array of shape (n_states, 1), the precision of the Normal prior distribution for the means. Defaults to 0.\n",
    "    :type means_weight: array_like, optional \n",
    "    :param means: array of shape (n_states, n_emissions) containing the mean parameters for each state\n",
    "    :type means: array_like \n",
    "    :param covars_prior: array of shape (n_states, 1), the mean of the Normal prior distribution for the covariance matrix. Defaults to 0.\n",
    "    :type covars_prior: array_like, optional \n",
    "    :param covars_weight: array of shape (n_states, 1), the precision of the Normal prior distribution for the covariance. Defaults to 0.\n",
    "    :type covars_weight: array_like, optional \n",
    "    :param min_covar: floor on the diagonal of the covariance matrix to prevent overfitting. Defaults to 1e-3.\n",
    "    :type min_covar: float, optional\n",
    "    :param covars: covariance parameters for each state arranged in an array\n",
    "        of shape depends `covariance_type`.\n",
    "    :type covars: array_like \n",
    "    :param learning_rate: a value from [0,1), controlling how much the past values of the model parameters count when computing the new model parameters during training; defaults to 0.\n",
    "    :type learning_rate: float, optional\n",
    "    :param verbose: flag to be set to True if per-iteration convergence reports should be printed, defaults to True\n",
    "    :type verbose: bool, optional\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_states,\n",
    "        n_g_emissions,\n",
    "        n_d_emissions,\n",
    "        n_d_features,\n",
    "        tr_params='stmce',\n",
    "        init_params='stmce',\n",
    "        nr_no_train_de=0,\n",
    "        state_no_train_de=None,\n",
    "        covariance_type='diagonal',\n",
    "        pi_prior=1.0,\n",
    "        A_prior=1.0,\n",
    "        means_prior=0,\n",
    "        means_weight=0,\n",
    "        covars_prior=1e-2,\n",
    "        covars_weight=1,\n",
    "        min_covar=1e-3,\n",
    "        learning_rate=0,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        \"\"\"Constructor method.\n",
    "\n",
    "        :raises ValueError: if covariance_type is not one of ('diagonal', 'full', 'tied', 'spherical')\n",
    "        :raises ValueError: if init_type is not one of ('uniform', 'random')\n",
    "        :raises TypeError: if n_d_features is not a list of length n_d_emissions\n",
    "        \"\"\"\n",
    "        if covariance_type not in COVARIANCE_TYPES:\n",
    "            raise ValueError(\n",
    "                'covariance_type must be one of {}'.format(COVARIANCE_TYPES)\n",
    "            )\n",
    "\n",
    "        if len(n_d_features) != n_d_emissions:\n",
    "            raise TypeError(\n",
    "                'n_d_features must be one of length {}'.format(n_d_emissions)\n",
    "            )\n",
    "\n",
    "        BaseHMM.__init__(\n",
    "            self,\n",
    "            n_states,\n",
    "            tr_params=tr_params,\n",
    "            init_params=init_params,\n",
    "            init_type='kmeans',\n",
    "            pi_prior=pi_prior,\n",
    "            A_prior=A_prior,\n",
    "            learning_rate=learning_rate,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        self.n_g_emissions = n_g_emissions\n",
    "        self.n_d_emissions = n_d_emissions\n",
    "        self.n_d_features = n_d_features\n",
    "        self.nr_no_train_de = nr_no_train_de\n",
    "        self.state_no_train_de = state_no_train_de\n",
    "        self.covariance_type = covariance_type\n",
    "        self.means_prior = means_prior\n",
    "        self.means_weight = means_weight\n",
    "        self.covars_prior = covars_prior\n",
    "        self.covars_weight = covars_weight\n",
    "        self.min_covar = min_covar\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Function to allow directly printing the object.\"\"\"\n",
    "        temp = super().__str__()\n",
    "        return (\n",
    "            temp\n",
    "            + '\\nMeans:\\n'\n",
    "            + str(self.means)\n",
    "            + '\\nCovariances:\\n'\n",
    "            + str(self.covars)\n",
    "            + '\\nB:\\n'\n",
    "            + str(self.B)\n",
    "        )\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "    #        Public methods. These are callable when using the class.         #\n",
    "    # ----------------------------------------------------------------------- #\n",
    "    @property\n",
    "    def covars(self):\n",
    "        \"\"\"Return covariances as a full matrix.\"\"\"\n",
    "        return fill_covars(\n",
    "            self._covars, self.covariance_type, self.n_states, self.n_g_emissions\n",
    "        )\n",
    "\n",
    "    @covars.setter\n",
    "    def covars(self, new_covars):\n",
    "        \"\"\"Setter for covariances. It expects the input to be of a corresponding shape to the 'covariance_type'.\n",
    "        \"\"\"\n",
    "        covars = np.array(new_covars, copy=True)\n",
    "        validate_covars(covars, self.covariance_type, self.n_states)\n",
    "        self._covars = covars\n",
    "\n",
    "    def get_n_fit_scalars_per_param(self):\n",
    "        \"\"\" Return a dictionary containing the number of trainable variables\n",
    "        for each model parameter.\n",
    "        \"\"\"\n",
    "        ns = self.n_states\n",
    "        neg = self.n_g_emissions\n",
    "        ned = self.n_d_emissions\n",
    "        nf = self.n_d_features\n",
    "        return {\n",
    "            's': ns,\n",
    "            't': ns * ns,\n",
    "            'm': ns * neg,\n",
    "            'c': {\n",
    "                'spherical': ns,\n",
    "                'diagonal': ns * neg,\n",
    "                'full': ns * neg * (neg + 1) // 2,\n",
    "                'tied': neg * (neg + 1) // 2,\n",
    "            }[self.covariance_type],\n",
    "            'e': sum(ns * (nf[i] - 1) for i in range(ned)),\n",
    "        }\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "    #             Private methods. These are used internally only.            #\n",
    "    # ----------------------------------------------------------------------- #\n",
    "    def _init_model_params(self, X):\n",
    "        \"\"\"Initialises model parameters prior to fitting. Extends the base classes method. See _BaseHMM.py for more information.\n",
    "        \"\"\"\n",
    "        super()._init_model_params()\n",
    "\n",
    "        X_concat = concatenate_observation_sequences(\n",
    "            X, gidx=self.n_g_emissions)\n",
    "\n",
    "        if 'm' in self.init_params:\n",
    "            kmeans = cluster.KMeans(n_clusters=self.n_states, random_state=0)\n",
    "            kmeans.fit(X_concat)\n",
    "            self.means = kmeans.cluster_centers_\n",
    "        if 'c' in self.init_params:\n",
    "            cv = np.cov(X_concat.T) + self.min_covar * \\\n",
    "                np.eye(self.n_g_emissions)\n",
    "            self._covars = init_covars(cv, self.covariance_type, self.n_states)\n",
    "        if 'e' in self.init_params:\n",
    "            if self.nr_no_train_de == 0:\n",
    "                self.B = [\n",
    "                    np.full(\n",
    "                        (self.n_states, self.n_d_features[i]),\n",
    "                        (1.0 / self.n_d_features[i]),\n",
    "                    )\n",
    "                    for i in range(self.n_d_emissions)\n",
    "                ]\n",
    "            else:\n",
    "                check_if_attributes_set(self, attr='e')\n",
    "\n",
    "    def _initialise_sufficient_statistics(self):\n",
    "        \"\"\"Initialises sufficient statistics required for M-step. Extends the base classes method by adding the emission probability matrix. See _BaseHMM.py for more information.\n",
    "        \"\"\"\n",
    "        stats = super()._initialise_sufficient_statistics()\n",
    "\n",
    "        stats['post'] = np.zeros(self.n_states)\n",
    "        stats['obs'] = np.zeros((self.n_states, self.n_g_emissions))\n",
    "        stats['obs**2'] = np.zeros((self.n_states, self.n_g_emissions))\n",
    "        if self.covariance_type in ('tied', 'full'):\n",
    "            stats['obs*obs.T'] = np.zeros(\n",
    "                (self.n_states, self.n_g_emissions, self.n_g_emissions)\n",
    "            )\n",
    "\n",
    "        stats['B'] = {\n",
    "            'numer': [\n",
    "                np.zeros((self.n_states, self.n_d_features[i]))\n",
    "                for i in range(self.n_d_emissions)\n",
    "            ],\n",
    "            'denom': [\n",
    "                np.zeros((self.n_states, self.n_d_features[i]))\n",
    "                for i in range(self.n_d_emissions)\n",
    "            ],\n",
    "        }\n",
    "        return stats\n",
    "\n",
    "    def _accumulate_sufficient_statistics(\n",
    "        self, stats, obs_stats, obs_seq\n",
    "    ):\n",
    "        \"\"\"Updates sufficient statistics from a given sample. Extends the base classes method. See _BaseHMM.py for more information.\n",
    "        \"\"\"\n",
    "        super()._accumulate_sufficient_statistics(\n",
    "            stats, obs_stats\n",
    "        )\n",
    "\n",
    "        if 'm' in self.tr_params:\n",
    "            stats['post'] += obs_stats['gamma'].sum(axis=0)\n",
    "            stats['obs'] += self._reestimate_stat_obs(\n",
    "                obs_stats['gamma'], obs_seq\n",
    "            )\n",
    "\n",
    "        if 'c' in self.tr_params:\n",
    "            if self.covariance_type in ('spherical', 'diagonal'):\n",
    "                stats['obs**2'] += self._reestimate_stat_obs2(\n",
    "                    obs_stats['gamma'], obs_seq\n",
    "                )\n",
    "            elif self.covariance_type in ('tied', 'full'):\n",
    "                stats['obs*obs.T'] += self._reestimate_stat_obs2(\n",
    "                    obs_stats['gamma'], obs_seq\n",
    "                )\n",
    "\n",
    "        if 'e' in self.tr_params:\n",
    "            B_new = self._reestimate_B(\n",
    "                [obs[self.n_g_emissions:] for obs in obs_seq],\n",
    "                obs_stats['gamma'],\n",
    "            )\n",
    "            for i in range(self.n_d_emissions):\n",
    "                stats['B']['numer'][i] += B_new['numer'][i]\n",
    "                stats['B']['denom'][i] += B_new['denom'][i]\n",
    "\n",
    "    def _reestimate_stat_obs(self, gamma, obs_seq):\n",
    "        \"\"\"Helper method for the statistics accumulation. Computes the sum of\n",
    "        the posteriors times the observations for the update of the means.\n",
    "\n",
    "        :param gamma: array of shape (n_samples, n_states), the posteriors\n",
    "        :type gamma: array_like\n",
    "        :param obs_seq: an observation sequence\n",
    "        :type obs_seq: array_like\n",
    "        \"\"\"\n",
    "        stat_obs = np.zeros_like(self.means)\n",
    "        for j in range(self.n_states):\n",
    "            for t in range(len(obs_seq)):\n",
    "                obs = obs_seq[t][: self.n_g_emissions]\n",
    "                if np.any(obs is np.nan) or np.any(obs != obs):\n",
    "                    # If there are missing observation we infer from the conditional posterior\n",
    "                    stat_obs[j] = stat_obs[j] + gamma[t][j] * self._infer_missing(\n",
    "                        obs, j\n",
    "                    )\n",
    "                else:\n",
    "                    # If there are no missing values we take this observation into account\n",
    "                    stat_obs[j] = stat_obs[j] + gamma[t][j] * obs\n",
    "        return stat_obs\n",
    "\n",
    "    def _reestimate_stat_obs2(self, gamma, obs_seq):\n",
    "        \"\"\"Helper method for the statistics accumulation. Computes the sum of\n",
    "        the posteriors times the square of the observations for the update\n",
    "        of the covariances.\n",
    "\n",
    "        :param gamma: array of shape (n_samples, n_states), the posteriors\n",
    "        :type gamma: array_like\n",
    "        :param obs_seq: an observation sequence\n",
    "        :type obs_seq: array_like\n",
    "        \"\"\"\n",
    "        if self.covariance_type in ('tied', 'full'):\n",
    "            stat_obs2 = np.zeros(\n",
    "                (self.n_states, self.n_g_emissions, self.n_g_emissions)\n",
    "            )\n",
    "        else:\n",
    "            stat_obs2 = np.zeros((self.n_states, self.n_g_emissions))\n",
    "\n",
    "        for j in range(self.n_states):\n",
    "            for t in range(len(obs_seq)):\n",
    "                obs = obs_seq[t][: self.n_g_emissions]\n",
    "                if np.any(obs is np.nan) or np.any(obs != obs):\n",
    "                    # If there are missing observation we infer from the conditional posterior\n",
    "                    obs = self._infer_missing(obs, j)\n",
    "                if self.covariance_type in ('tied', 'full'):\n",
    "                    stat_obs2[j] = stat_obs2[j] + \\\n",
    "                        gamma[t][j] * np.outer(obs, obs)\n",
    "                else:\n",
    "                    stat_obs2[j] = stat_obs2[j] + np.dot(gamma[t][j], obs ** 2)\n",
    "        return stat_obs2\n",
    "\n",
    "    def _infer_missing(self, obs, state):\n",
    "        \"\"\"Helper method for the statistics accumulation. It infers the missing\n",
    "        observation from the conditional posterior for a given state.\n",
    "\n",
    "        :param obs: a single observation\n",
    "        :type obs: array_like\n",
    "        :param state: the index of the hidden state to consider\n",
    "        :type state: int\n",
    "        \"\"\"\n",
    "        # If all the features of the obs_seq are missed, it is not necessary\n",
    "        # to use this observation to update the means and covars. So we set them to 0.\n",
    "        if np.all(obs is np.nan) or np.all(obs != obs):\n",
    "            return np.zeros_like(obs)\n",
    "        # For partial obs_seq we compute the conditional posterior.\n",
    "        elif (np.any(obs is np.nan) or np.any(obs != obs)) and not (\n",
    "            np.all(obs is np.nan) or np.all(obs != obs)\n",
    "        ):\n",
    "            _, _, obs_vector = self._calc_conditional_posterior(obs, state)\n",
    "            return obs_vector\n",
    "\n",
    "    def _reestimate_B(self, obs_seq, gamma):\n",
    "        \"\"\"Re-estimation of the emission matrix (part of the 'M' step of Baum-Welch). Computes B_new = expected # times in state s_j with symbol v_k /expected # times in state s_j\n",
    "\n",
    "        :param obs_seq: array of shape (n_samples, n_d_features)\n",
    "                containing the observation samples\n",
    "        :type obs_seq: array_like\n",
    "        :param gamma: posteriors, array of shape (n_samples, n_states)\n",
    "        :type gamma: array_like\n",
    "        :return: the modified parts of the emission matrix\n",
    "        :rtype: dict\n",
    "        \"\"\"\n",
    "        B_new = {\n",
    "            'numer': [\n",
    "                np.zeros((self.n_states, self.n_d_features[i]))\n",
    "                for i in range(self.n_d_emissions)\n",
    "            ],\n",
    "            'denom': [\n",
    "                np.zeros((self.n_states, self.n_d_features[i]))\n",
    "                for i in range(self.n_d_emissions)\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        for e in range(self.n_d_emissions):\n",
    "            for j in range(self.n_states):\n",
    "                for k in range(self.n_d_features[e]):\n",
    "                    numer = 0.0\n",
    "                    denom = 0.0\n",
    "                    for t, obs in enumerate(obs_seq):\n",
    "                        if obs[e] == k:\n",
    "                            numer += gamma[t][j]\n",
    "                        denom += gamma[t][j]\n",
    "                    B_new['numer'][e][j][k] = numer\n",
    "                    B_new['denom'][e][j][k] = denom\n",
    "\n",
    "        return B_new\n",
    "\n",
    "    def _M_step(self, stats):\n",
    "        \"\"\"Required extension of M_step. Adds a re-estimation of the parameters 'means', 'covars' and 'B'.\n",
    "        \"\"\"\n",
    "        new_model = super()._M_step(stats)\n",
    "\n",
    "        denom = stats['post'][:, np.newaxis]\n",
    "        if 'm' in self.tr_params:\n",
    "            new_model['means'] = (\n",
    "                self.means_weight * self.means_prior + stats['obs']\n",
    "            ) / (self.means_weight + denom)\n",
    "\n",
    "        if 'c' in self.tr_params:\n",
    "            meandiff = new_model['means'] - self.means_prior\n",
    "            if self.covariance_type in ('spherical', 'diagonal'):\n",
    "                cv_num = (\n",
    "                    self.means_weight * meandiff ** 2\n",
    "                    + stats['obs**2']\n",
    "                    - 2 * new_model['means'] * stats['obs']\n",
    "                    + new_model['means'] ** 2 * denom\n",
    "                )\n",
    "                cv_den = np.amax(self.covars_weight - 1, 0) + denom\n",
    "                covars_new = (self.covars_prior + cv_num) / \\\n",
    "                    np.maximum(cv_den, 1e-5)\n",
    "                if self.covariance_type == 'spherical':\n",
    "                    covars_new = covars_new.mean(1)\n",
    "            elif self.covariance_type in ('tied', 'full'):\n",
    "                cv_num = np.empty(\n",
    "                    (self.n_states, self.n_g_emissions, self.n_g_emissions)\n",
    "                )\n",
    "                for c in range(self.n_states):\n",
    "                    obs_mean = np.outer(stats['obs'][c], new_model['means'][c])\n",
    "                    cv_num[c] = (\n",
    "                        self.means_weight * np.outer(meandiff[c], meandiff[c])\n",
    "                        + stats['obs*obs.T'][c]\n",
    "                        - obs_mean\n",
    "                        - obs_mean.T\n",
    "                        + np.outer(new_model['means'][c],\n",
    "                                   new_model['means'][c])\n",
    "                        * stats['post'][c]\n",
    "                    )\n",
    "                cvweight = np.amax(self.covars_weight - self.n_g_emissions, 0)\n",
    "                if self.covariance_type == 'tied':\n",
    "                    covars_new = (self.covars_prior + cv_num.sum(axis=0)) / (\n",
    "                        cvweight + stats['post'].sum()\n",
    "                    )\n",
    "                elif self.covariance_type == 'full':\n",
    "                    covars_new = (self.covars_prior + cv_num) / (\n",
    "                        cvweight + stats['post'][:, None, None]\n",
    "                    )\n",
    "            new_model['covars'] = covars_new\n",
    "\n",
    "        if 'e' in self.tr_params:\n",
    "            new_model['B'] = [\n",
    "                stats['B']['numer'][i] / stats['B']['denom'][i]\n",
    "                for i in range(self.n_d_emissions)\n",
    "            ]\n",
    "\n",
    "        return new_model\n",
    "\n",
    "    def _update_model(self, new_model):\n",
    "        \"\"\" Required extension of _updatemodel. Adds 'B', 'means' and 'covars',\n",
    "        which holds the in-state information.\n",
    "        \"\"\"\n",
    "        super()._update_model(new_model)\n",
    "\n",
    "        if 'm' in self.tr_params:\n",
    "            self.means = (1 - self.learning_rate) * new_model[\n",
    "                'means'\n",
    "            ] + self.learning_rate * new_model['means']\n",
    "\n",
    "        if 'c' in self.tr_params:\n",
    "            self._covars = (1 - self.learning_rate) * new_model[\n",
    "                'covars'\n",
    "            ] + self.learning_rate * self._covars\n",
    "\n",
    "        if 'e' in self.tr_params:\n",
    "            if self.state_no_train_de is None:\n",
    "                for i in range(self.n_d_emissions - self.nr_no_train_de):\n",
    "                    self.B[i] = (1 - self.learning_rate) * new_model['B'][\n",
    "                        i\n",
    "                    ] + self.learning_rate * self.B[i]\n",
    "            else:\n",
    "                for i in range(self.n_d_emissions):\n",
    "                    if i < self.n_d_emissions - self.nr_no_train_de:\n",
    "                        self.B[i] = (1 - self.learning_rate) * new_model['B'][\n",
    "                            i\n",
    "                        ] + self.learning_rate * self.B[i]\n",
    "                    else:\n",
    "                        self.B[i][: -self.state_no_train_de, :] = (\n",
    "                            (1 - self.learning_rate)\n",
    "                            * new_model['B'][i][: -self.state_no_train_de, :]\n",
    "                            + self.learning_rate *\n",
    "                            self.B[i][: -self.state_no_train_de, :]\n",
    "                        )\n",
    "            for i in range(self.n_d_emissions):\n",
    "                normalise(self.B[i], axis=1)\n",
    "\n",
    "    def _map_B(self, obs_seq):\n",
    "        \"\"\"Required implementation for _map_B. Refer to _BaseHMM for more details.\n",
    "        \"\"\"\n",
    "\n",
    "        def _map_gB(y_t, j):\n",
    "            \"\"\"\n",
    "            Implementation of _map_B for the Gaussian emissions.\n",
    "            \"\"\"\n",
    "            if np.all(y_t is np.nan or y_t != y_t):\n",
    "                # 1st Case: Complete Missed Observation. For more details see GaussianHMM\n",
    "                obs = self.means[j]\n",
    "            elif np.any(y_t is np.nan or y_t != y_t):\n",
    "                # 2nd Case: Partially Missing Observation\n",
    "                _, _, obs = self._calc_conditional_posterior(y_t, j)\n",
    "            else:\n",
    "                obs = y_t\n",
    "            return self._pdf(obs, self.means[j], self.covars[j])\n",
    "\n",
    "        def _map_dB(y_t, j):\n",
    "            \"\"\"Implementation of _map_B for the multinomial emissions.\n",
    "            \"\"\"\n",
    "            bjt = 1.0\n",
    "            for e, symbol in enumerate(y_t):\n",
    "                if symbol is np.nan or symbol != symbol:\n",
    "                    bjt *= self.B[e][j][np.argmax(self.B[e][j])]\n",
    "                else:\n",
    "                    bjt *= self.B[e][j][int(symbol)]\n",
    "            return bjt\n",
    "\n",
    "        B_map = np.zeros((self.n_states, len(obs_seq)))\n",
    "\n",
    "        for j in range(self.n_states):\n",
    "            for t in range(len(obs_seq)):\n",
    "                bjt_gauss = _map_gB(obs_seq[t][: self.n_g_emissions], j)\n",
    "                bjt_disc = _map_dB(obs_seq[t][self.n_g_emissions:], j)\n",
    "                B_map[j][t] = bjt_gauss * bjt_disc\n",
    "\n",
    "        return B_map\n",
    "\n",
    "    def _calc_conditional_posterior(self, obs, state):\n",
    "        \"\"\"Helper function to compute the posterior conditional probability of the missing features given the not missing ones:  p(missing|not_missing) = Gaussian(missing | mean(missing|not_missing), covariance(missing|not_missing). For extra information regarding the mathematical development of this case, you can consult the 4.3.1 section (Inference in jointly Gaussian distributions)\n",
    "        of Kevin Murphy's book: Machine Learning, a probabilistic perspective.\n",
    "        On the code, we use the '1' to refer to the missing features of the\n",
    "        observation and the '2' to refer to the not missing features when\n",
    "        naming the variables.\n",
    "\n",
    "        :param obs: a single observation\n",
    "        :type obs: array_like\n",
    "        :param state: the index of the hidden state to consider\n",
    "        :type state: int\n",
    "        \"\"\"\n",
    "\n",
    "        nan_index = np.asarray(\n",
    "            [True if (ot is np.nan or ot != ot) else False for ot in obs]\n",
    "        )\n",
    "\n",
    "        mu_1 = self.means[state][nan_index]\n",
    "        mu_2 = self.means[state][~nan_index]\n",
    "        sigma_11 = self._calc_sigma(state, nan_index, sigma_flat='11')\n",
    "        sigma_12 = self._calc_sigma(state, nan_index, sigma_flat='12')\n",
    "        sigma_21 = self._calc_sigma(state, nan_index, sigma_flat='21')\n",
    "        sigma_22 = self._calc_sigma(state, nan_index, sigma_flat='22')\n",
    "        sigma_22 += self.min_covar * np.eye(sigma_22.shape[0])\n",
    "\n",
    "        sigma_1_given_2 = sigma_11 - np.matmul(\n",
    "            np.matmul(sigma_12, np.linalg.inv(sigma_22)), sigma_21\n",
    "        )\n",
    "        mu_1_given_2 = mu_1 + np.matmul(\n",
    "            np.matmul(sigma_12, np.linalg.inv(\n",
    "                sigma_22)), (obs[~nan_index] - mu_2)\n",
    "        )\n",
    "\n",
    "        obs_vector = np.zeros_like(obs)\n",
    "        obs_vector[~nan_index] = obs[~nan_index]\n",
    "        obs_vector[nan_index] = mu_1_given_2\n",
    "\n",
    "        return mu_1_given_2, sigma_1_given_2, obs_vector\n",
    "\n",
    "    def _calc_sigma(self, state, nan_index, sigma_flat):\n",
    "        \"\"\"Helper function for the _calc_conditional_posterior function.\n",
    "\n",
    "        :param state: the index of the hidden state to consider\n",
    "        :type state: int\n",
    "        :param nan_index: contains the indices of NaN elements in the observation\n",
    "        :type nan_index: array_like\n",
    "        :param sigma_flat: indicator of which calculation to use\n",
    "        :type sigma_flat: str\n",
    "        :return: the computed covariance values\n",
    "        :rtype: array_like\n",
    "        \"\"\"\n",
    "\n",
    "        number_missing_features = np.sum(nan_index)\n",
    "        number_non_missing_features = np.sum(~nan_index)\n",
    "\n",
    "        if sigma_flat == '11':\n",
    "            cond_1 = True\n",
    "            cond_2 = True\n",
    "            shape_1 = number_missing_features\n",
    "            shape_2 = number_missing_features\n",
    "        elif sigma_flat == '12':\n",
    "            cond_1 = True\n",
    "            cond_2 = False\n",
    "            shape_1 = number_missing_features\n",
    "            shape_2 = number_non_missing_features\n",
    "        elif sigma_flat == '21':\n",
    "            cond_1 = False\n",
    "            cond_2 = True\n",
    "            shape_1 = number_non_missing_features\n",
    "            shape_2 = number_missing_features\n",
    "        elif sigma_flat == '22':\n",
    "            cond_1 = False\n",
    "            cond_2 = False\n",
    "            shape_1 = number_non_missing_features\n",
    "            shape_2 = number_non_missing_features\n",
    "\n",
    "        tmp = []\n",
    "        for i in range(self.n_g_emissions):\n",
    "            for j in range(self.n_g_emissions):\n",
    "                if nan_index[i] == cond_1 and nan_index[j] == cond_2:\n",
    "                    tmp.append(self.covars[state][i, j])\n",
    "\n",
    "        res = np.array(tmp).reshape((shape_1, shape_2))\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _pdf(self, x, mean, covar):\n",
    "        \"\"\" Multivariate Gaussian PDF function. \n",
    "\n",
    "        :param x: a multivariate sample \n",
    "        :type x: array_like\n",
    "        :param mean: mean of the distribution \n",
    "        :type mean: array_like\n",
    "        :param covar: covariance matrix of the distribution\n",
    "        :type covar: array_like\n",
    "        :return: the PDF of the sample\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        if not np.all(np.linalg.eigvals(covar) > 0):\n",
    "            covar = covar + self.min_covar * np.eye(self.n_g_emissions)\n",
    "        return multivariate_normal.pdf(x, mean=mean, cov=covar, allow_singular=True)\n",
    "\n",
    "    def _generate_sample_from_state(self, state):\n",
    "        \"\"\" Generates a random sample from a given component.\n",
    "        :param state: index of the component to condition on\n",
    "        :type state: int\n",
    "        :return: array of shape (n_g_features+n_d_features, ) containing a random sample\n",
    "            from the emission distribution corresponding to a given state\n",
    "        :rtype: array_like\n",
    "        \"\"\"\n",
    "        gauss_sample = np.random.multivariate_normal(\n",
    "            self.means[state], self.covars[state]\n",
    "        )\n",
    "\n",
    "        cat_sample = []\n",
    "        for e in range(self.n_d_emissions):\n",
    "            cdf = np.cumsum(self.B[e][state, :])\n",
    "            cat_sample.append((cdf > np.random.rand()).argmax())\n",
    "\n",
    "        return np.concatenate([gauss_sample, cat_sample])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
